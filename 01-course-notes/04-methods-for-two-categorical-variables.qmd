---
title: "Chapter 4: Methods for Two Categorical Variables"
embed-resources: true
format: 
  html:
    toc: true
  pdf:
    keep-tex: false
    include-in-header:
      text: |
          \usepackage{fancyhdr}
          \pagestyle{fancy}
          \fancyhf{}
          \fancyhead[R]{Chapter 4: Methods for Two Categorical Variables}
          \fancyfoot[C]{\thepage}
  docx:
    toc: false
bibliography: references.bib
reference-location: section
execute:
  echo: false
  message: false
  warning: false
---

Until this point, we have been working with **one categorical variable** with two or more levels (*toy* - helper/hinder; *font* - signet/salem; *season* - fall/winter/spring/summer). In this set of notes, we will introduce and investigate research questions, statistical analyses, and interpretation for **two categorical variables**.

## Example 4.1: MythBusters and the Yawning Experiment

MythBusters, a popular television program on the Discovery Channel, once conducted an experiment to investigate whether or not yawning is contagious. The premise of the experiment was to invite a stranger to sit in a booth for an extended period of time. Fifty subjects were said to be tested in total, of which 34 were "seeded" with a yawn by the person conducting the experiment. The other 16 were not given a yawn seed. Using a two-way mirror and a hidden camera, the experimenters observed and recorded the data which is shown below:

```{r simulate-data}
#| include: false
#| eval: false
library(tidyverse)

set.seed(56156)
myth_busters <- tibble(id = sample(1:50, 50),
                       combo = c(rep("Seeded-Yawned", 11),
                                 rep("Seeded-NoYawn", 23),
                                 rep("Control-Yawned", 3),
                                 rep("Control-NoYawn", 13)
                                 ),
                   age_years = round(runif(50, min = 18, max = 55), 0)
                 
) |> 
  separate_wider_delim(cols = combo, names =  c("seeding", "action"), delim = "-") |> 
  mutate(seeding = factor(seeding, levels = c("Seeded", "Control")),
         action = factor(action, levels = c("Yawned", "NoYawn"))
         ) |> 
  arrange(id) |> 
  select(-id)

write.csv(myth_busters, "data/myth_busters.csv", row.names = F)
```

```{r}
#| echo: true
library(tidyverse) # <1> 
myth_busters <- read_csv("data/myth_busters.csv") # <2>
head(myth_busters) # <3>
```

1.  Load the `tidyverse` package
2.  Read in the `myth_busters` data set
3.  Print the top 6 rows of the `myth_busters` data set

**Research Question:** Do these data provide statistical evidence there is a *relationship* between yawn seeding and yawn action?

When we analyze data on two variables, our first step is to distinguish between the *response variable* and the *explanatory* (or *predictor*) *variable*.

::: callout-note
-   **Response variable:** The outcome variable on which comparisons are made.

-   **Explanatory (or predictor) variable:** This defines the groups to be compared.
:::

1.  What are the variables in the MythBusters Yawning experiment? Are they categorical or numerical? Which is the response variable? Which is the explanatory variable?

\vspace{2in}

::: callout-note
### Descriptive Methods for Two Categorical Variables:

-   A **bar plot** gives a visual representation of the relationship between two categorical variables. A bar plot graphically presents the information given in the contingency table. The x-axis of the graph denotes the categories of the *explanatory variable*, and the *fill* color denotes the categories of the *response variable*. We can create three types of bar plots -- filled (my fav!), stacked, or dodged.

\vspace{0.1in}

-   A **contingency table** shows the joint counts (aka frequencies) of two categorical variables. The *rows* of the table denote the categories of the *explanatory variable*, and the *columns* denote the categories of the *response variable*.

:::

```{r}
#| echo: true
#| eval: false
ggplot(data = myth_busters, # <1>
       mapping = aes(x = seeding,  # <2>
                     fill = action # <3>
                     )
       ) + 
  geom_bar(position = "fill") +  # <4>
  labs(title = "Filled bar plot",  # <5>
       x = "Seeding Group",
       y = "Proportion of Subjects")
```

1.  Tell your plot which data set to get the information from.
2.  Tell the plot which variable you want on the x-axis (typically explanatory).
3.  Tell the plot which variable you want to color by (typically response).
4.  Create the bars and indicate `position = ` -- "fill", "stack", or "dodge".
5.  Provide appropriate plot titles and axis labels.

```{r}
#| echo: false
#| fig-pos: "H"
#| fig-width: 12
#| fig-height: 3
library(patchwork)
g_fill <- ggplot(data = myth_busters,
       mapping = aes(x = seeding,
                     fill = action)) +
  geom_bar(position = "fill") +
  labs(title = "Filled bar plot",
       x = "Seeding Group",
       y = "Proportion of Subjects"
       )

g_stack <- ggplot(data = myth_busters,
       mapping = aes(x = seeding,
                     fill = action)) +
  geom_bar(position = "stack") +
  labs(title = "Stacked bar plot",
       x = "Seeding Group",
       y = "Number of Subjects"
       )

g_dodge <- ggplot(data = myth_busters,
       mapping = aes(x = seeding,
                     fill = action)) +
  geom_bar(position = "dodge") +
  labs(title = "Dodged bar plot",
       x = "Seeding Group",
       y = "Number of Subjects"
       )

g_fill + g_stack + g_dodge
```

Previously, we saw how we can summarize the counts from our data set using `count(VARIABLE)`. This is helpful, but notice we get one column for each count.

```{r}
#| echo: true
myth_busters |> # <1>
  count(seeding, action) # <2>
```

1.  Start with the `myth_busters` data set
2.  Count the number of subjects in each seeding group and yawn action combination

It is easier to understand the relationship between the explanatory and response variables if we arrange our counts into a contingency table:

```{r}
#| echo: true
library(janitor)  # <1>

myth_busters |> # <2>
  tabyl(seeding, action) |>  # <3>
  adorn_totals(where = c("row", "col"))  # <4>
```

1. Load the `janitor` package to access specific functions.
2. Start with the `myth_busters` data set.
3. Use the `tabyl` function to count the number of subjects in each seeding group and yawn action combination, and arrange in a contingency table format.
4. Use the `adorn_totals()` function to add total counts to the contingency table.

\vspace{0.1in}

2.  Find the proportion that yawn in the Seeded group.

\vspace{0.5in}

3.  Find the proportion that yawn in the Control group.

\vspace{0.5in}

We could instead obtain our observed proportion that yawn (and did not yawn) for each group using `adorn_percentages()`.

```{r}
#| echo: true
myth_busters |> 
  tabyl(seeding, action) |> 
  adorn_totals(where = c("row", "col")) |> 
  adorn_percentages(denominator = "row") # <5>
```

5.  Calculate the observed proportions based on the "row" totals (number of subjects in each seeding group).

### Chi-square Test of Independence

The above descriptive analysis tells us what we have learned about the 50 subjects in the study. Can we make any inferences beyond what happened in the study (i.e., general statements about the population)? Similar to what we did in Chapter 3 with the Chi-square Goodness of Fit Test for one categorical variablewith more than two groups, we will be simulating and calculating a Chi-Squared Test Statistic to compare what we observed in the data to what we would have expected to see under the assumption that yawn seeding has no relationship with yawn action (i.e., if the null hypothesis is true).

4.  Write the null and alternative hypotheses for this study.

\vspace{1.5in}

::: callout-note
### Expected Counts under $H_0$

The Chi-Squared Test Statistic ($X^2$) has exactly the same formula to what we used last week. The only aspect that changes is how we get each cell's expected count.

To find the expected count for each cell in our two variable table, we use three pieces of information:

-   the row total for that cell (denoted with an $i$)
-   the column total for that cell (denoted with a $j$)
-   the total sample size

We find the expected value of a cell using the following formula:

$$\frac{\text{row}_i\text{ total} \times \text{column}_j\text{ total}}{\text{total sample size}}.$$
:::

Once we have each of these, we can create a table of what counts we would have expected *under* the assumption there is no relationship between seeding group and yawn action (i.e., if the null is true).

5.  Complete the table of Expected counts.

**Observed counts**

```{r}
myth_busters |> 
  count(seeding, action) |> 
  pivot_wider(names_from = action,
              values_from = n) |> 
  adorn_totals(where = c("row", "col")) |> 
  knitr::kable()
```

**Expected counts** under assumption null is true (no relationship between seeding and action)


+---------------------+--------------+--------------+--------------+
|                     | No yawn      | Yawned       | Total        |
+---------------------+--------------+--------------+--------------+
| Control             | \            |              | 36           |
|                     | \            |              |              |
+---------------------+--------------+--------------+--------------+
| Seeded              | \            |              | 34           |
|                     | \            |              |              |
+---------------------+--------------+--------------+--------------+
| Total               | 36           | 14           | 50           |
+---------------------+--------------+--------------+--------------+

**Chi-Square Test Statistic** Next, we compare each of our observed counts to what we would have expected if $H_0$ was true. We compare how far "off" our observed frequencies are from what was expected using the same formula we saw in Chapter 3.

$$
\text{Test Statistic} =\sum\frac{\text{(Observed - Expected)}^2}{\text{Expected}} 
$$

Using the formula above, we can calculate how far "off" each of the cells in our observed table is from what we expected under the assumption there is no relationship between seeding and yawn action.

$$
X^2 =\frac{(13-11.52)^2}{11.52}+\frac{(3-4.48)^2}{4.48}+\frac{(23-24.48)^2}{24.48}+\frac{(11-9.52)^2}{9.52}=0.999
$$

\newpage

#### Conducting a Simulation Study with Two Variables

We will answer the research question by replicating the experiment over and over again, but *under* the assumption that yawn seeding has no relationship with yawn action (i.e., the null is true). We'll start with 14 yawners and 36 non-yawners, and we'll randomly assign 34 of these 50 subjects to the seeded group and the remaining 16 to the non-seeded group.

**Step 1:** Write the action (yawned/ did not yawn) and the seeding (seeded with a yawn / not seeded with a yawn) on \_\_\_\_\_\_\_ cards.

**Step 2:** Assume the null hypothesis is true (no relationship) and

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_.

**Step 3:** Create a new dataset that could have happened if $H_0$ was true by

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_.

**Step 4:** Construct the contingency table of your simulated counts from the shuffled/randomly matched cards to show the number of yawners and non-yawners in each seeding group.

*Keep in mind the column totals and the row totals will stay the same (there were only 14 people who yawned, and only 34 people who were seeded with a yawn). However, the cell values will change (we won't always have 10 individuals who Yawned from being seeded with a yawn).*

**Simulated Counts**

+---------------------+--------------+--------------+--------------+
|                     | No yawn      | Yawned       | Total        |
+---------------------+--------------+--------------+--------------+
| Control             | \            |              | 36           |
|                     | \            |              |              |
+---------------------+--------------+--------------+--------------+
| Seeded              | \            |              | 34           |
|                     | \            |              |              |
+---------------------+--------------+--------------+--------------+
| Total               | 36           | 14           | 50           |
+---------------------+--------------+--------------+--------------+

6. Divide your simulated counts by the row totals to give you the proportion of individuals who yawned and did not yawn for each seeding group. Sketch these in the second plot below. How do your simulated proportions compare to the observed proportions?

```{r}
#| out-width: 80%
#| fig-align: center
#| fig-pos: "H"
knitr::include_graphics("04-images/yawn-bar-sketch.png")
```

**Step 5:** Calculate the $X^2$ text statistic for your simulated counts under the assumption there is no relationship between seeding group and yawn action.

*Recall our expected counts will be the same for every simulation (and the same as for our observed test statistic calculation.*

\vspace{1.3in}

**Step 6:** Plot the simulated $X^2$ test statistic on the dot plot below. Add your group member's dots.

```{r}
#| out-width: 80%
#| fig-align: center
#| fig-pos: "H"
knitr::include_graphics("04-images/yawn-dot-sketch.png")
```

7.  How does the observed test statistic compare to the simulated test statistics by your group members? Does this provide evidence for or against the alternative? Explain.

\vspace{0.8in}

We can conduct a large scale simulation using `Online Simulation Applets` \> `Two-way Tables`.

-   Clear \> Copy/Paste in the data <https://raw.githubusercontent.com/earobinson95/stat218-calpoly/refs/heads/main/01-course-notes/data/myth-yawns.csv>
-   Click `Use Data`
-   Click `Show Shuffle Options`
-   Change `Statistic` to $X^2$.
-   Change `Number of Shuffles` to 1000, and hit `Shuffle`

```{r}
#| out-width: 70%
#| fig-align: center
#| fig-pos: "H"
knitr::include_graphics("04-images/yawn-sim.PNG")
```

8. What does each "dot" on the above plot represent?

\vspace{0.8in}

9. How often did we see results at least as extreme as the observed test statistic under assumption the null is true? Estimate the p-value from the simulation. What decision would you make about the research question?

\vspace{0.8in}

10. State your conclusion in terms of the research question.

\vspace{0.8in}

#### Using The Chi-Square Distribution

Recall the Chi-square distribution can be used to approximate our simulated null sampling distribution of the test statistic to test for a relationship between the explanatory and response variables. The Chi-square distribution takes on only positive numbers. In addition, this distribution is indexed by its degrees of freedom (or df).

::: callout-note
## Degrees of Freedom (df) for the Chi-Square Test of Independence:
When the null hypothesis is true, the test-statistic follows the Chi-square distribution with df = (rows - 1)(columns - 1).
:::

The R code below would be used to conduct a Chi-square Test for the Myth Busters study:

```{r}
#| echo: true
#| warning: true
library(infer) # <1>
chisq_test(x = myth_busters, # <2>
           explanatory = seeding, # <3>
           response = action, # <4>
           correct = FALSE  # <5>
           )
```

1. Load the `infer` package to access specific functions.
2. Use the `chisq_test()` function and denote the data set `x = `.
3. Specify the `explanatory = ` variable name,
4. and the `response = ` variable name.
5. We will not talk about corrections, but the default is `TRUE` and we want `FALSE`.

::: callout-note
### Conditions for conducting a Chi-square Test:

In order for the $\chi^2$ distribution to be a good approximation of the sampling distribution under the assumption the null is true, we need to verify two conditions:

-   The observations are independent
-   We have a "large enough" sample size
    -   This is checked by verifying there are at least 5 expected counts in each category

If the condition about expected cell counts is violated, we are forced to use the simulation-based method.
:::

11. Check the conditions for using a Chi-square distribution to analyze the Myth Buster's study. Is it appropriate to conduct a Chi-square Test?

\vspace{1.5in}

Notice the plot below shows the Chi-square distribution is not a very good approximation of our simulated sampling distribution of our test statistic. Therefore, we want to be cautious about using the theory-based Chi-square Test.

```{r}
#| out-width: 40%
#| fig-align: center
#| fig-pos: "H"
knitr::include_graphics("04-images/yawn-chisq-approx.PNG")
```

```{r}
#| echo: true
#| warning: true
library(infer)
chisq_test(x = myth_busters,
           explanatory = seeding,
           response = action,
           correct = FALSE,
           simulate.p.value = TRUE # <6>
           )
```

6. In order to conduct a *simulation* instead, specify `simulate.p.value = TRUE`. Notice we no longer have `chisq_df`.

## Example 4.2: Vested Interest and Task Performance

*This example is from Investigating Statistical Concepts, Applications, and Methods by Beth Chance and Allan Rossman. 2006. Thomson-Brooks/Cole.*

"A study published in the Journal of Personality and Social Psychology (Butler and Baumeister, 1998) investigated a conjecture that having an observer with a vested interest would decrease subjects' performance on a skill-based task. Subjects were given time to practice playing a video game that required them to navigate an obstacle course as quickly as possible. They were then told to play the game one final time with an observer present. Subjects were randomly assigned to one of two groups. One group (A) was told that the participant and observer would each win \$3 if the participant beat a certain threshold time, and the other group (B) was told only that the participant would win the prize if the threshold were beaten. The threshold was chosen to be a time that they beat in 30% of their practice turns. The following results are very similar to those found in the experiment: 3 of the 12 subjects in group A beat the threshold, and 8 of 12 subjects in group B achieved success."

|                         | Achieved Success | Did not achieve success | Total |
|-------------------------|:----------------:|:-----------------------:|:-----:|
| A: Vested Interest      |        3         |            9            |  12   |
| B. No Vested Interest   |        8         |            4            |  12   |
| Total                   |       11         |           13            |  24   |

**Research Question:** Does whether the observer has a vested interest or not have an impact on performance on a skill-based task?

1.  What are the variables in the study? Are they categorical or numerical? Which is the explanatory variable? Which is the response variable?

\vspace{0.8in}

2.  Convert the research question into your null and alternative hypotheses.

\vspace{1.2in}


3. Is it appropriate to use the Chi-square distribution or do we need to use simulation?

\vspace{0.8in}

4.  Using the simulation output below, determine the p-value. Make a decision concerning the null hypothesis.

```{r}
#| out-width: 50%
#| fig-align: center
knitr::include_graphics("04-images/vested-interest-sim.PNG")
```

\vspace{0.8in}

5.  Write a conclusion in terms of the original research question. Make sure to include your evidence in your conclusion.

\vspace{1.5in}

## Example 4.3 High-Salt Diets and Cardiovascular Disease

Suppose a retrospective study is carried out among men aged 50-54 in a specific county who died over a one-month period. The investigators try to include approximately an equal number of men who died from CVD (the cases) and men who died from other causes (the controls). Of 15 people who died from CVD, 4 were on a high-salt diet before they died. In contrast, of 15 people who died from other causes, only 1 was on a high-salt diet. The data are shown in the following contingency table:

|         |           |          |       |
|---------|:---------:|:--------:|:-----:|
|         | High-Salt | Low-Salt | Total |
| Non-CVD |     1     |    14    |  15   |
| CVD     |     4     |    11    |  15   |
| Total   |     5     |    25    |  30   |

**Research Question:** Is there an association between the cause of death and salt diet? In other words, is the proprtion of the CVD group which has a high-salt diet different from the proportion of the Non-CVD group which has a high-salt diet?

1.  What are the variables in the study? Which is the response variable? Which is the explanatory variable?

\vspace{0.8in}

2.  Convert the research question into your null and alternative hypotheses.

\vspace{1.2in}

3. Is it appropriate to use the Chi-square distribution or do we need to use simulation?

\vspace{0.8in}

4.  Using the simulation output below, determine the p-value. Make a decision concerning the null hypothesis.

```{r}
#| out-width: 50%
#| fig-align: center
knitr::include_graphics("04-images/cvd-sim.PNG")
```

\vspace{0.8in}

5.  Write a conclusion in terms of the original research question. Make sure to include your evidence in your conclusion.

\vspace{1.5in}

## Observational Studies vs. Designed Experiments

Let’s reconsider the "Vested Interest and Task Performance" example. Our simulated results showed an association between the group (vested interest vs. no vested interest) and task performance (Acheieved Success vs Did not achieve success). But can we confidently say that having a vested interest causes the difference in performance? Similarly, in the "High-Salt Diet and Cardiovascular Disease" example, if there were evidence to reject the null, could we conclude that high-salt diets cause cardiovascular disease? The answer depends on the study's design—whether it was a designed experiment or an observational study.

::: callout-note
## Definitions
-   An **observational study** involves collecting and analyzing data without manipulating or randomly assigning treatments. The data exists naturally, and we can only identify *associations* between variables.

-   A **designed experiment**, however, involves randomly assigning treatments or groups to individuals to investigate whether the treatment *causes* a change in the response variable. The study is manipulated to control other variables.
:::

::: callout-tip
## Key statistical idea:
In **observational studies**, we can only establish that an *association* exists between the explanatory and response variables. This is because other uncontrolled factors, or confounding variables, could influence the response. Since these factors aren’t balanced between groups, they might explain the observed differences.

\vspace{0.1in}

In **designed experiments**, *random assignment* helps balance confounding variables across treatment groups, controlling for their influence. Therefore, designed experiments can provide evidence of a *cause-and-effect* relationship.
:::

In the *"Vested Interest and Task Performance"* study, participants were randomly assigned to groups, making this a designed experiment. The randomization likely balanced out other factors that could influence performance, meaning the reduced performance in the vested interest group is most likely *caused* by the vested interest itself.

\vspace{0.1in}

In contrast, the *"High-Salt Diet and Cardiovascular Disease"* study is an observational study. Other factors, like overall health behaviors (e.g., exercise habits), could explain the *association* between a high-salt diet and cardiovascular disease. Therefore, we can’t confidently conclude causation from this study.

## Example 4.4: Alcoholism and Depression

Past research has suggested a high rate of alcoholism in families among patients with primary unipolar depression. A study of 210 families of females with primary unipolar depression found that 89 families had alcoholism present. A set of 299 control families found 94 present.

**Research Question:** Does the proportion of families afflicted by alcoholism differ between those families in which the female has primary unipolar depression and the control group? That is, is there a relationship between unipolar depression in females and alocholism in the family?

```{r simulate-data2}
#| include: false
#| eval: false
library(tidyverse)

set.seed(56156)
alcoholism <- tibble(id = sample(1:509, 509),
                       combo = c(rep("Control-Yes", 94),
                                 rep("Depression-Yes", 89),
                                 rep("Control-No", 205),
                                 rep("Depression-No", 121)
                                 )
                 
) |> 
  separate_wider_delim(cols = combo, names =  c("group", "alcoholism"), delim = "-") |> 
  arrange(id) |> 
  select(-id)

write.csv(alcoholism, "data/alcoholism.csv", row.names = F)
```

```{r}
alcoholism <- read_csv("data/alcoholism.csv")
```

```{r}
alcoholism |> 
  tabyl(group, alcoholism) |>
  adorn_totals(where = c("row", "col")) |> 
  knitr::kable()
```

1.  What are the variables in the study? Which is the response variable? Which is the explanatory variable?

\vspace{0.8in}

2.  Identify the proportion of families afflicted by Alcoholism in both groups.

\vspace{1.2in}

3.  Convert the research question into your null and alternative hypotheses.

\vspace{1.2in}

4. Is it appropriate to use the Chi-square distribution or do we need to use simulation?

\vspace{0.8in}


5.  Is there evidence there a relationship between unipolar depression in females and alocholism in the family? Use the R output to answer this question. Make sure to include evidence in your conclusion.

```{r}
#| echo: true
library(infer)
chisq_test(alcoholism,
           response = alcoholism,
           explanatory = group,
           correct = FALSE
           )
```

\vspace{1.2in}

6.  Can we say that having unipolar depression *causes* alcoholism? Explain your reasoning.

\vspace{1.2in}

\newpage

::: callout-tip
## Key statistical idea: Scope of Inference


The **scope of inference** in a study refers to what conclusions can be drawn based on how the data were collected. If a study uses random assignment, it allows for causal conclusions because differences in outcomes can be attributed to the treatment or group. However, random sampling allows for results to be generalized to the broader population. Without random assignment, we can only infer associations, not causation, and without random sampling, the findings can only be applied to the specific sample studied, limiting generalizability.

```{r}
knitr::include_graphics("04-images/scope-of-inference.png")
```

:::