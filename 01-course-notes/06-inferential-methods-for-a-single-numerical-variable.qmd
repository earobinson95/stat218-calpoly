---
title: "Chapter 6: Inferential Methods for a Single Numerical Variable"
format: 
  html:
    toc: true
  pdf:
    keep-tex: false
    include-in-header:
      text: |
          \usepackage{fancyhdr}
          \pagestyle{fancy}
          \fancyhf{}
          \fancyhead[R]{Chapter 6: Inferential Methods for a Single Numerical Variable}
          \fancyfoot[C]{\thepage}
  docx:
    toc: false
prefer-html: true
embed-resources: true
bibliography: references.bib
reference-location: section
execute:
  echo: false
  message: false
  warning: false
---

As seen in earlier chapters, research hypotheses involving either a single categorical variable or two categorical variables require us to test claims about population proportions. When a research question involves a single numerical variable, however, we end up testing claims about the population mean (or average) based on a sample. In this chapter, we will consider inferential methods (hypothesis tests and confidence intervals) for the population mean of a single numerical variable. Consider the following example.

::: callout-note
## Notation for Means

**Sample** (these are statistics)

+ $\bar x$ is the sample mean (think of this as $\hat p$ from proportions)

+ $s$ is the sample standard deviation

**Population** (these are parameters)

+ $\mu$ is the population mean (think of this as $\pi$ from proportions)

+ $\sigma$ is the population standard devation
:::

## Example 6.1: Time Perception Impaired by Nicotine Withdrawl

A study conducted by researchers at Pennsylvania State University investigated whether time perception, a simple indication of a person's ability to concentrate, is impaired during nicotine withdrawal. The study results were presented in the paper *Smoking Abstinence Impairs Time Estimation Accuracy in Cigarette Smokers* [@klein2003smoking]. After a 24-hour smoking abstinence, 20 daily smokers were asked to estimate how much time had passed during a 45-second period. Suppose the resulting data on perceived elapsed time (in seconds) were summarizied and visualized as shown below (these results are artificial but are similar to the actual findings).

\newpage

```{r nicotine-data}
library(tidyverse)
library(mosaic)
library(infer)

set.seed(24)
nicotine <- tibble(status = "withdrawl",
                   sex = c(rep("male", 12), rep("female", 8)),
                   age = runif(20, min = 25, max = 50),
                   time_passed = rnorm(n = 20, mean = 55.05, sd = 9.32)
                   ) |> 
  sample(20) |> 
  select(-orig.id)
```

```{r}
head(nicotine)
```

We can summarize the data with:

```{r}
#| echo: true
favstats( ~ time_passed, data = nicotine)
```

and visualize the data with:

```{r}
#| echo: true
#| eval: false
ggplot(data = nicotine,
       mapping = aes(x = time_passed)) +
  geom_histogram(binwidth = 5) +
  labs(title = "Distribution of our data",
       y = "Number of Subjects",
       x = "Perceived Elapsed Time (seconds)")
```

```{r}
#| fig-align: center
#| out-width: 70%
ggplot(data = nicotine,
       mapping = aes(x = time_passed)) +
  geom_histogram(binwidth = 5,
                 color = "white") +
  labs(title = "Time Estimation Accuracy from Cigarette Smokers",
       y = "Number of Subjects",
       x = "Perceived Elapsed Time (seconds)")
```

1.  Identify the following in context of the scenario:

+ Population:
\vspace{0.2in}

+ Sample:
\vspace{0.2in}

+ Variable of interest:
\vspace{0.2in}

+ Data Type:
\vspace{0.2in}

2.  What is the mean of the observed data? The standard deviation?

\vspace{0.2in}

3. If another sample of $n=20$ subjects were obtained, would these new subjects have a mean exactly the same as the mean from this sample? Why or why not?


\vspace{0.3in}

4.  Given your answer to the previous question, do you think it is appropriate to use only this sample mean to make inferences about the mean perceived elapsed time in the greater population of all smokers subjected to nicotine withdrawal? Explain.

\vspace{0.3in}

### The Distribution of the Sample Mean

The sample mean is a random quantity that changes from sample to sample. This randomness gives the sample mean its own distribution, called the distribution of the sample mean, which tells us:

+ The possible values the sample mean can assume.
+ How often each value will occur.

Understanding this distribution is key to making decisions about the population mean for a single numerical variable. Let’s explore how sample means behave by simulating repeated samples.

## Exploring the Distribution of the Sampling Mean

We will use an applet (<https://posit.cloud/spaces/556082/content/9064163>) to simulate drawing random samples from a population and observe the distribution of sample means.

The goal is to simulate multiple samples of $n = 20$ drawn from a hypothetical population of smokers experiencing nicotine withdrawal.

**Step 1: Population Parameters** We begin by setting up a hypothetical population of **all** smokers suffering from nicotine withdraw. 

In this simulation study, what are the following parameters for your population?

$\mu$ = _____ -- Where does this value of 45 seconds come from? *yours might differ slightly*

\vspace{0.05in}

$\sigma$ = _____

\vspace{0.1in}

What does each dot on this plot represent?

\vspace{0.1in}

**Step 2: Repeated Samples** In practice, we usually don’t know the true population mean ($\mu$). Researchers often take random samples to estimate this mean. In our case, we’ll simulate multiple random samples of 20 subjects.

+ *Sample 1:* Click "Draw Samples". Record the sample mean and sample standard deviation:

$\bar x_{sample 1}$ = _____

\vspace{0.05in}

$s_{sample 1}$ = _____

\vspace{0.1in}

What does each dot on this plot represent?

\vspace{0.1in}

+ *Sample 2:* Click "Draw Samples" again. Record the new values:

$\bar x_{sample 2}$ = _____

\vspace{0.05in}

$s_{sample 2}$ = _____

\vspace{0.1in}

+ *Sample 3:* Click "Draw Samples" once more. Record:

$\bar x_{sample 3}$ = _____

\vspace{0.05in}

$s_{sample 3}$ = _____

\vspace{0.1in}

*Compare:* How do the means and standard deviations from these three samples differ?

**Step 3: Distribution of Sample Means:** Each of these sample means is a single point from the *distribution of sample means*. Let’s now visualize the distribution of sample means:

\vspace{0.05in}

Add a dot on the plot for each sample mean from the three samples you took above.

```{r}
#| fig-align: center
#| out-width: 80%
knitr::include_graphics("06-images/dist-of-sample-means-sketch.png")
```

**Next:** To get a better sense of this distribution, increase the "Number of Samples" to 100 and hit "Draw Samples" to generate more sample means. Record the overall mean and standard deviation from the "Distribution of Sample Means".

\vspace{0.05in}

+ Distribution Mean = _____
+ Distribution SD = _____

\vspace{0.05in}

What does each dot on this plot represent?

\vspace{0.2in}

**Step 4: Hypothesis Testing** The researchers hypothesized that the mean perceived elapsed time for smokers during nicotine withdrawal was greater than 45 seconds. Let’s formally define the hypotheses:

> $H_0$:  The mean perceived elapsed time for *all* smokers suffering from nicotine withdrawal is *equal* to 45 seconds.

> $H_A$: The mean perceived elapsed time for *all* smokers suffering from nicotine withdrawal is *greater* than 45 seconds.

The "Distribution of Sample Means" assumes the null hypothesis is true. It shows what we expect sample means to look like if the true population mean really is 45 seconds.

**Step 5: Observed Data** Recall, in the actual research study, the mean perceived elapsed time for 20 subjects was 52.65 seconds. Sketch this observed value on the "Distribution of Sample Means" you generated.

Estimate the p-value: Based on the simulation, what is the probability of obtaining a sample mean of 52.65 seconds or greater, assuming the null hypothesis is true?

Estimated p-value = ______

**Step 6: Understanding the Central Limit Theorem (CLT)**

Rather than always using simulations, statisticians rely on a theoretical result called the *Central Limit Theorem (CLT)*. The CLT allows us to make inferences about the population mean without needing to take repeated samples.

::: callout-note
### The Central Limit Theorem (CLT)

The Central Limit Theorem (CLT) allows us to approximate the *distribution of sample means* as normal, provided the sample size is large enough.

+ **Mean of Sample Means**: The *distribution of sample means* will be centered around the population mean $\mu$. This means that, on average, the sample mean will be a good estimate of the population mean.

+ **Standard Error (SE):** The standard deviation of the *distribution of sample means* is called the standard error. It tells us how much the sample means tend to vary from the population mean:

$$SE = \frac{\sigma}{\sqrt{n}}$$

+ **When is the CLT valid?** For most situations, the CLT applies well if the sample size is 30 or larger. If the sample size is smaller than 30, the population should be normally distributed. For populations that are strongly skewed or have outliers, larger samples may be necessary for the CLT to hold.
:::

+ Check the Shape:  Does the "Distribution of Sample Means" look approximately normal?

\vspace{0.05in}

+ Recall from Step 1: The population parameters were $\mu =$ ___ and $\sigma =$ _____.

\vspace{0.05in}

+ Calculate the Standard Error (SE): We call the standard deviation of the distribution of sample means the standard error. It represents how much variability we expect in the sample means if we repeatedly take samples from the population.

> $SE = \frac{\sigma}{\sqrt{n}} =$ ______. 


**Step 7: Comparing Simulation Results and Theory** 

Compare the values from your simulation with the theoretical values based on the CLT:

+ From Step 3: Mean = _____, SD = _____

\vspace{0.05in}

+ From Step 6: SE = _____

How does simulated standard deviation compare to the theoretical SE?

\vspace{0.2in}

:::callout-note
## Key Statistical Concepts

The Central Limit Theorem allows us to estimate the population mean using a single sample, knowing that:

1. The distribution of sample means will be approximately normal if the sample size is large enough.

2. The sample means will be centered around the true population mean, $\mu$.

3. The variability of the sample means is determined by the standard error $\frac{\sigma}{\sqrt{n}}$, which decreases as the sample size increases.

You can access a fun applet for exploring Sampling Distributions and the CLT further at <https://onlinestatbook.com/stat_sim/sampling_dist/index.html>.
:::

In the next section, we will use the CLT to perform hypothesis tests using a procedure called the t-test.

## The t-test for a Single Population Mean

Back to **Example 6.1:** Recall that the researchers wanted to show that the mean perceived elapsed time for smokers suffering from nicotine withdrawal was greater than the actual 45 seconds that had elapsed. The data collected in the study were summarized as follows:

```{r}
library(mosaic)
favstats( ~ time_passed, data = nicotine)
```

```{r}
#| fig-align: center
#| out-width: 70%
ggplot(data = nicotine,
       mapping = aes(x = time_passed)) +
  geom_histogram(binwidth = 5,
                 color = "white") +
  labs(title = "Time Estimation Accuracy from Cigarette Smokers",
       y = "Number of Subjects",
       x = "Perceived Elapsed Time (seconds)")
```
**Setup**

1. What is the parameter of interest?

\vspace{0.8in}

2.  Set up the null and alternative hypotheses

$H_0$: 

\vspace{0.8in}

$H_A$:

\vspace{0.8in}


\newpage

**Find the t-statistic and the p-value**

To determine whether or not the distance between $\mu$ (the hypothesized population mean, null value) and (the mean from our observed sample) is larger than what we would expect by random chance, we will use the following statistic:

$$T = \frac{\bar x - \mu_0}{s/\sqrt{n}} =$$

Why use this statistic? Because this quantity measures the position of our observed sample mean on the null model, just like the Z-score discussed in the previous chapter.

$$T = \frac{\bar x - \mu_0}{s/\sqrt{n}} = \frac{\text{observed sample mean - mean of the distribution of sample means}}{\text{standard error}}$$

Note that this is very much like the Z-score, with one minor exception. We don't know the true population standard deviation, $\sigma$, so we estimate it with the standard deviation calculated from the 20 observed subjects in the study (this estimate is commonly denoted by $s$).

This t-statistic comes from what is called a t-distribution. The amount of variability in a t-distribution depends on the sample size n. Therefore, this distribution is indexed by its *degrees of freedom* (df).

::: callout-note
### Degrees of Freedom for a Single Mean

For inference on a single mean, $df = n - 1$.
:::

To find the p-value associated with this test statistic, we must remember that this is an upper-tailed test (we are trying to find evidence that the mean is greater than 45 seconds). So, the p-value will be the probability we would observe a sample mean (or a t-statistic) greater than that obtained in the actual study by chance alone, assuming the null hypothesis is true:

```{r}
#| out-width: 55%
#| fig-align: center
#| fig-pos: "H"
#| fig-cap: <https://homepage.divms.uiowa.edu/~mbognar/applets/t.html>
knitr::include_graphics("06-images/nicotine-withdrawl-t.PNG")
```

Note that in practice, we can use R to test our research question:

```{r}
#| echo: true

t_test(x = nicotine, # <1>
       response = time_passed, # <2>
       mu = 45, # <3>
       alternative = "greater", # <4>
       )
```
1. Use the `t_test()` function from the `infer` package and designate your `x = ` data set.
2. Tell the function the `response = ` variable of interest,
3. and the `mu = ` null value ($\mu_0$).
4. Specify the direction of the `alternative = ` hypothesis.

**Conclusion**

3.  Write a conclusion in context of the problem.

\vspace{1.4in}

::: callout-note
### Checking the Normality Assumption:

For the t-test to be valid, at least one of the following conditions must be met:

-   Either the sample size is sufficiently large (greater than 30 or so), OR
-   The distribution of the observed data is approximately normal (which would indicate that the population is normally distributed so that the Central Limit Theorem would apply even with a small sample size)
:::

For Example 6.1, we have a sample size of 20 subjects, which is not sufficiently large. So we must check whether the data seem to come from a normal distribution. 

4. Look back at the histogram of the original data. Does this seem to indicate that this is a reasonable assumption?

\vspace{0.6in}

## Example 6.2: Time Perception for Smokers NOT Suffering from Nicotine Withdrawl

For the data given in Example 6.1, we found evidence that the mean perceived elapsed was in fact greater than the actual 45 seconds that had elapsed. This study alone, however, doesn't really say that the nicotine withdrawal was what impaired one's perception of time. Why not?

Suppose that the researchers also studied 22 subjects who were smokers that did NOT abstain from smoking prior to the data collection (so, they were not suffering from nicotine withdrawal).

**Research Question:** Is there evidence the mean perceived elapsed time for all smokers **NOT** suffering from nicotine withdrawal is significantly greater than the actual 45 seconds?

```{r}
set.seed(24)
nowithdrawl_data <- tibble(status = "no withdrawl",
                   sex = c(rep("male", 12), rep("female", 10)),
                   age = runif(22, min = 25, max = 50),
                   time_passed = rnorm(n = 22, mean = 46.85, sd = 9.35)
                   ) |> 
  slice_sample(n = 22)
```

```{r}
#| echo: true
head(nowithdrawl_data)
```

Carry out the formal t-test to address this research question.

1.  Set up the null and alternative hypotheses

> $H_0:$

\vspace{0.8in}

> $H_A:$

\vspace{0.8in}

2.  Check normality assumptions for using the CLT.

```{r}
#| echo: true
favstats( ~ time_passed, data = nowithdrawl_data)
```

```{r}
#| fig-align: center
#| out-width: 70%
ggplot(data = nowithdrawl_data,
       mapping = aes(x = time_passed)) +
  geom_histogram(binwidth = 5,
                 color = "white") +
  labs(title = "Time Estimation Accuracy from Smokers with No Withdrawl",
       y = "Number of Subjects",
       x = "Perceived Elapsed Time (seconds)")
```

\vspace{1.2in}

3.  Find the t-statistic *(practice calculating this out)* and the p-value.

```{r}
#| out-width: 60%
#| fig-align: center
#| fig-pos: "H"
#| fig-cap: <https://homepage.divms.uiowa.edu/~mbognar/applets/t.html>
knitr::include_graphics("06-images/nonsmoker_tapplet.PNG")
```

```{r}
#| echo: true
t_test(x = nowithdrawl_data,
       response = time_passed,
       mu = 45,
       alternative = "greater"
       )
```

\vspace{0.8in}

4.  Write a conclusion in the context of the problem.

\vspace{1.2in}

## Confidence Interval for a Single Population Mean

In **Example 6.1**, we found evidence that the mean perceived elapsed time for smokers suffering from nicotine withdrawal differed from the actual 45 seconds of time that had elapsed. Our next question is obvious: HOW MUCH does it differ? To answer this question, we must construct a confidence interval.

Recall our discussion of confidence intervals from earlier in the quarter:

This procedure does NOT require any hypotheses concerning our population parameter of interest (the population mean, in this case). We will use both our sample data (in particular, the observed mean) and what we know about the *distribution of sample means* to obtain a range of likely values for our population mean.

::: callout-warning
+ A confidence interval allows us to *estimate the population parameter* of interest (recall that the hypothesis test does NOT allow us to do this). Therefore, when available, a confidence interval should always accompany the hypothesis test.

+ The confidence interval does not require any hypothesized value for the population parameter. Instead, we center the confidence interval on the sample mean. Consider the following example.
:::

## Example 6.3: Estimated Perceived Time from Nicotine Withdrawl

Our goal is to construct a 95\% confidence interval for the mean perceived elapsed time for smokers suffering from nicotine withdrawal (Example 6.1). To do this, we will center our distribution of sample means on the observed sample mean. Then, we will find the lower and upper endpoints that separate the middle 95\% of the distribution from the rest (since we are constructing a 95\% confidence interval).

Recall the general form of a confidence interval:

$$\text{point estimate} \pm \text{multiplier} \times \text{SE}.$$

Thus, the formula for calculating the endpoints of a confidence interval for a mean is given as follows:

$$\bar x \pm \text{t-quantitle}\times\big(\frac{s}{\sqrt{n}}\big)$$

The appropriate t-quantile can be found using R *(typically I will give you a table to choose from)* To find this value, you need the following information:

\vspace{0.2in}

```{r}
#| echo: true
qt(0.975, df = 19)
```

\vspace{0.2in}

+ confidence level =

\vspace{0.2in}

+ df =

\vspace{0.2in}

Also, recall our summary statistics for time passed from Example 6.1:

```{r}
#| echo: true
favstats( ~ time_passed, data = nicotine)
```

1. Use this information to find the endpoints of the confidence interval:

+ Lower endpoint = $\bar x - \text{t-quantitle}\times\big(\frac{s}{\sqrt{n}}\big)$

\vspace{1.2in}

+ Upper endpoint = $\bar x + \text{t-quantitle}\times\big(\frac{s}{\sqrt{n}}\big)$

\vspace{1.2in}

\newpage

Note that we can ask R to provide the endpoints of the 95\% confidence interval for this mean when we use the `t_test` function with a `two-sided` test. We can change the confidence level with the `conf_level` argument.

```{r}
#| echo: true
t_test(x = nicotine,
       response = time_passed,
       mu = 45,
       alternative = "two.sided", # <4>
       conf_level = 0.95 # <5>
       )
```

4. Change the `alternative = ` to a two-sided test (CI are always two-sided),
5. and specify the `conf_level = `.

\vspace{0.2in}

2.  Interpret the meaning of this interval. What does this interval tell us about the true mean perceived elapsed time for all smokers that are suffering from nicotine withdrawal?

\vspace{1.4in}

3.  Does this interval agree with what you learned from the hypothesis test? Explain.

\vspace{1.2in}

\newpage

4.  How would your calculations change if you wanted to obtain a 90\% confidence interval, instead?

```{r}
#| echo: true
qt(0.90, df = 19)
qt(0.95, df = 19)
qt(0.975, df = 19)
qt(0.995, df = 19)
```

\vspace{1.2in}







<!-- OLD STUFF -->

<!-- ```{r} -->
<!-- #| fig-height: 4 -->
<!-- #| fig-width: 8 -->
<!-- #| fig-align: center -->
<!-- set.seed(7) -->
<!-- nicotine_population <- tibble(time_passed = rnorm(n = 1000, mean = 45, sd = 7.3)) -->

<!-- ggplot(data = nicotine_population, -->
<!--        mapping = aes(x = time_passed)) + -->
<!--   geom_dotplot(method = "histodot", -->
<!--                dotsize = 0.1) + -->
<!--   geom_vline(xintercept = mean(nicotine_population$time_passed), color = "steelblue", size = 1) + -->
<!--   geom_text(aes(label = round(mean(nicotine_population$time_passed), 1),  -->
<!--                 x = mean(nicotine_population$time_passed),  -->
<!--                 y = Inf), -->
<!--             hjust = -0.5, -->
<!--             vjust = 3, -->
<!--             color = "steelblue" -->
<!--             ) + -->
<!--   labs(title = "Distribution of 'all' smokers", -->
<!--        x = "Perceived Elapsed Time (seconds)", -->
<!--        y = "") + -->
<!--   scale_x_continuous(limits = c(0,80), breaks = seq(0,80,5)) + -->
<!--   theme(axis.text.y = element_blank(), -->
<!--         axis.ticks.y = element_blank() -->
<!--         ) -->
<!-- ``` -->

<!-- \vspace{0.7in} -->

<!-- Note that in reality, the true population mean is usually an unknown quantity which we are trying to estimate.  Since it is not feasible to collect data on the entire population of smokers suffering from nicotine withdrawal, the researchers took a random sample of 20 subjects in order to estimate the average perceived elapsed time.  Let’s see what happens when we take various samples of size 20 from this population. -->

<!-- ```{r} -->
<!-- #| fig-width: 12 -->
<!-- #| fig-height: 4 -->
<!-- #| fig-align: center -->
<!-- set.seed(8) -->
<!-- s1 <- sample(nicotine_population, size = 20) -->

<!-- ggplot(data = s1, -->
<!--        mapping = aes(x = time_passed)) + -->
<!--   geom_dotplot(method = "histodot", -->
<!--                dotsize = 0.5) + -->
<!--   geom_vline(xintercept = mean(s1$time_passed), color = "steelblue", size = 1) + -->
<!--   geom_text(aes(label = round(mean(s1$time_passed), 1),  -->
<!--                 x = mean(s1$time_passed),  -->
<!--                 y = Inf), -->
<!--             hjust = -0.5, -->
<!--             vjust = 3, -->
<!--             color = "steelblue" -->
<!--             ) + -->
<!--   labs(title = "Sample 1", -->
<!--        x = "Perceived Elapsed Time (seconds)", -->
<!--        y = "") + -->
<!--   scale_x_continuous(limits = c(0,80), breaks = seq(0,80,5)) + -->
<!--   theme(axis.text.y = element_blank(), -->
<!--         axis.ticks.y = element_blank() -->
<!--         ) -->
<!-- ``` -->
<!-- 6. What is the average (or mean) perceived elapsed time of the 20 subjects in this "fake" study? -->

<!-- \vspace{0.7in} -->

<!-- 7. Does this necessarily mean that the average perceived elapsed time is greater than 45 seconds for all smokers suffering from nicotine withdrawal?  What would you say to a researcher who tried to use only this sample mean to draw this conclusion? -->

<!-- \vspace{0.7in} -->

<!-- Even though in reality we would carry out a study only once, we will take a sample of 20 subjects from this population over and over again so that we get an idea of how much the sample mean could change from sample to sample. Our second and third random samples of 20 subjects and their sample means are shown below: -->

<!-- ```{r} -->
<!-- #| fig-width: 12 -->
<!-- #| fig-height: 4 -->
<!-- #| fig-align: center -->
<!-- set.seed(5) -->
<!-- s2 <- sample(nicotine_population, size = 20) -->

<!-- ggplot(data = s2, -->
<!--        mapping = aes(x = time_passed)) + -->
<!--   geom_dotplot(method = "histodot", -->
<!--                dotsize = 0.5) + -->
<!--   geom_vline(xintercept = mean(s2$time_passed), color = "steelblue", size = 1) + -->
<!--   geom_text(aes(label = round(mean(s2$time_passed), 1),  -->
<!--                 x = mean(s2$time_passed),  -->
<!--                 y = Inf), -->
<!--             hjust = -0.5, -->
<!--             vjust = 3, -->
<!--             color = "steelblue" -->
<!--             ) + -->
<!--   labs(title = "Sample 3", -->
<!--        x = "Perceived Elapsed Time (seconds)", -->
<!--        y = "") + -->
<!--   scale_x_continuous(limits = c(0,80), breaks = seq(0,80,5)) + -->
<!--   theme(axis.text.y = element_blank(), -->
<!--         axis.ticks.y = element_blank() -->
<!--         ) -->
<!-- ``` -->

<!-- ```{r} -->
<!-- #| fig-width: 12 -->
<!-- #| fig-height: 4 -->
<!-- #| fig-align: center -->
<!-- set.seed(1) -->
<!-- s3 <- sample(nicotine_population, size = 20) -->

<!-- ggplot(data = s3, -->
<!--        mapping = aes(x = time_passed)) + -->
<!--   geom_dotplot(method = "histodot", -->
<!--                dotsize = 0.5) + -->
<!--   geom_vline(xintercept = mean(s3$time_passed), color = "steelblue", size = 1) + -->
<!--   geom_text(aes(label = round(mean(s3$time_passed), 1),  -->
<!--                 x = mean(s3$time_passed),  -->
<!--                 y = Inf), -->
<!--             hjust = -0.5, -->
<!--             vjust = 3, -->
<!--             color = "steelblue" -->
<!--             ) + -->
<!--   labs(title = "Sample 3", -->
<!--        x = "Perceived Elapsed Time (seconds)", -->
<!--        y = "") + -->
<!--   scale_x_continuous(limits = c(0,80), breaks = seq(0,80,5)) + -->
<!--   theme(axis.text.y = element_blank(), -->
<!--         axis.ticks.y = element_blank() -->
<!--         ) -->
<!-- ``` -->

<!-- We can start to collect these sample means in a new plot to create the *distribution of sample means*: -->

<!-- ```{r} -->
<!-- #| fig-width: 12 -->
<!-- #| fig-height: 4 -->
<!-- #| fig-align: center -->
<!-- #| fig-pos: "H" -->
<!-- sample_means <- tibble(means = c(mean(s1$time_passed), -->
<!--                        mean(s2$time_passed), -->
<!--                        mean(s3$time_passed) -->
<!--                        )) -->

<!-- ggplot(data = sample_means, -->
<!--        mapping = aes(x = means)) + -->
<!--   geom_dotplot(method = "histodot", -->
<!--                dotsize = 0.5) + -->
<!--   labs(title = "Distribution of Sample Means", -->
<!--        x = "Mean of Perceived Elapsed Time (seconds) \n n = 20", -->
<!--        y = "") + -->
<!--   scale_x_continuous(limits = c(35,55), breaks = seq(0,80,5)) + -->
<!--   theme(axis.text.y = element_blank(), -->
<!--         axis.ticks.y = element_blank() -->
<!--         ) -->
<!-- ``` -->




<!-- ```{r} -->
<!-- #| fig-pos: "H" -->
<!-- set.seed(1) -->
<!-- sample_means <- tibble(sim = 1:1000, -->
<!--                        n = 20) |>  -->
<!--   rowwise() |>  -->
<!--   mutate(means = mean(sample(nicotine_population$time_passed, size = 20))) -->

<!-- ggplot(data = sample_means, -->
<!--        mapping = aes(x = means)) + -->
<!--   geom_dotplot(method = "histodot", -->
<!--                dotsize = 0.08) + -->
<!--   labs(title = "Distribution of Sample Means", -->
<!--        x = "Mean of Perceived Elapsed Time (seconds) \n n = 20", -->
<!--        y = "") + -->
<!--   scale_x_continuous(limits = c(35,55), breaks = seq(0,80,5)) + -->
<!--   theme(axis.text.y = element_blank(), -->
<!--         axis.ticks.y = element_blank() -->
<!--         ) -->
<!-- ``` -->

<!-- This is a distribution of sample means.  Recall that these 1000 samples (each consisting of 20 subjects) came from a population with a true mean perceived elapsed time of 45 seconds. So, this distribution gives us a good idea of what sample means from 20 subjects are likely (or unlikely) to occur by chance *if the true mean is 45 seconds*. -->

<!-- Next, note that the researchers wanted to show that the mean perceived elapsed time for smokers suffering from nicotine withdrawal was in fact greater than 45 seconds.  The null and alternative hypotheses to address this research question are given as follows. -->

<!-- > $H_0$:  The mean perceived elapsed time for *all* smokers suffering from nicotine withdrawal is equal to 45 seconds. -->

<!-- > $H_A$: The mean perceived elapsed time for *all* smokers suffering from nicotine withdrawal is greater than 45 seconds. -->

<!-- Note that the distribution of sample means was created *assuming the null hypothesis is true*. To test this hypothesis, we compare our actual observed mean to this null distribution. If the sample mean from the actual research study is not likely to occur by chance according to this null model (i.e., if it is an outlier on this null distribution), then we have evidence against the null model and in support of the research question. -->

<!-- 8. Recall that in the actual research study, the mean perceived elapsed time for the 20 subjects studied was 52.65 seconds.  Sketch this observed value on the null distribution above. -->

<!-- \vspace{0.2in} -->

<!-- There are two explanations for this observed mean of 52.65 seconds: either (1) the true mean perceived elapsed time for smokers suffering from nicotine withdrawal really is greater than 45 seconds, or (2) their time perception is not impaired (i.e., the true mean is actually 45 seconds) and the sample mean was greater than 45 seconds simply because of random chance. -->

<!-- 9. Was a sample mean of 52.65 seconds likely to occur by chance if the true population mean is actually 45 seconds?  What does this imply about the research question? -->

<!-- \vspace{0.8in} -->


<!-- We can see the Central Limit Theorem applied to the sample means calculated from our hypothetical population from Example 6.2 as follows: -->

<!-- -   We see that the distribution of sample means is approximately normal: -->

<!-- ```{r} -->
<!-- #| fig-width: 8 -->
<!-- #| fig-height: 4 -->
<!-- #| fig-align: center -->
<!-- nicotine_norm <- tibble("x" = seq(35, 55, 0.001), -->
<!--                            "dnorm" = dnorm(x,  -->
<!--                                            mean = mean(sample_means$means),  -->
<!--                                            sd = sd(sample_means$means) -->
<!--                            )) -->

<!-- ggplot(data = sample_means, -->
<!--        mapping = aes(x = means)) + -->
<!--   geom_dotplot(method = "histodot", -->
<!--                dotsize = 0.08) + -->
<!--   geom_line(data = nicotine_norm, -->
<!--             aes(x = x, -->
<!--                 y = dnorm -->
<!--                 ), -->
<!--             color = "steelblue", -->
<!--             size = 1 -->
<!--             ) + -->
<!--   labs(title = "Distribution of Sample Means", -->
<!--        x = "Mean of Perceived Elapsed Time (seconds) \n n = 20", -->
<!--        y = "") + -->
<!--   scale_x_continuous(limits = c(35,55), breaks = seq(0,80,5)) + -->
<!--   theme(axis.text.y = element_blank(), -->
<!--         axis.ticks.y = element_blank() -->
<!--         ) + -->
<!--   scale_y_continuous(limits = c(0,0.285)) -->
<!-- ``` -->

<!-- -   We see that this normal distribution is centered at *about* the true population mean, $\mu = 45$. -->

<!-- ```{r} -->
<!-- favstats(~ means, data = sample_means) -->
<!-- ``` -->


<!-- -   The standard deviation of all observations in our hypothetical population is $\sigma =$ r round(sd(nicotine_population$time_passed), 2) seconds. According to the central limit theorem, then, the standard deviation of the distribution of sample means is given by -->

<!-- $$\frac{\sigma}{\sqrt n} = \frac{7.17}{\sqrt{20}}=1.60$$ -->