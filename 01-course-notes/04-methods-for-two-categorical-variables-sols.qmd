---
title: "Chapter 4: Methods for Two Categorical Variables"
embed-resources: true
format: 
  html:
    toc: true
  # pdf:
  #   keep-tex: false
  #   include-in-header:
  #     text: |
  #         \usepackage{fancyhdr}
  #         \pagestyle{fancy}
  #         \fancyhf{}
  #         \fancyhead[R]{Chapter 4: Methods for Two Categorical Variables}
  #         \fancyfoot[C]{\thepage}
  # docx:
  #   toc: false
bibliography: references.bib
reference-location: section
execute:
  echo: false
  message: false
  warning: false
---

Until this point, we have been working with **one categorical variable** with two or more levels (*toy* - helper/hinder; *font* - signet/salem; *season* - fall/winter/spring/summer). In this set of notes, we will introduce and investigate research questions, statistical analyses, and interpretation for **two categorical variables**.

## Example 4.1: MythBusters and the Yawning Experiment

MythBusters, a popular television program on the Discovery Channel, once conducted an experiment to investigate whether or not yawning is contagious. The premise of the experiment was to invite a stranger to sit in a booth for an extended period of time. Fifty subjects were said to be tested in total, of which 34 were "seeded" with a yawn by the person conducting the experiment. The other 16 were not given a yawn seed. Using a two-way mirror and a hidden camera, the experimenters observed and recorded the data which is shown below:

```{r simulate-data}
#| include: false
#| eval: false
library(tidyverse)

set.seed(56156)
myth_busters <- tibble(id = sample(1:50, 50),
                       combo = c(rep("Seeded-Yawned", 11),
                                 rep("Seeded-NoYawn", 23),
                                 rep("Control-Yawned", 3),
                                 rep("Control-NoYawn", 13)
                                 ),
                   age_years = round(runif(50, min = 18, max = 55), 0)
                 
) |> 
  separate_wider_delim(cols = combo, names =  c("seeding", "action"), delim = "-") |> 
  mutate(seeding = factor(seeding, levels = c("Seeded", "Control")),
         action = factor(action, levels = c("Yawned", "NoYawn"))
         ) |> 
  arrange(id) |> 
  select(-id)

write.csv(myth_busters, "data/myth_busters.csv", row.names = F)
```

```{r}
#| echo: true
library(tidyverse) # <1> 
myth_busters <- read_csv("data/myth_busters.csv") # <2>
head(myth_busters) # <3>
```

1.  Load the `tidyverse` package
2.  Read in the `myth_busters` data set
3.  Print the top 6 rows of the `myth_busters` data set

**Research Question:** Do these data provide statistical evidence there is a *relationship* between yawn seeding and yawn action?

When we analyze data on two variables, our first step is to distinguish between the *response variable* and the *explanatory* (or *predictor*) *variable*.

::: callout-note
-   **Response variable:** The outcome variable on which comparisons are made.

-   **Explanatory (or predictor) variable:** This defines the groups to be compared.

The *explanatory variable* is the variable we think is “explaining” the change in the response variable and the *response variable* is the variable we think is being impacted or changed by the explanatory variable. The explanatory variable is sometimes called the independent variable and the response variable is sometimes called the dependent variable.
:::

1.  What are the variables in the MythBusters Yawning experiment? Are they categorical or numerical? Which is the response variable? Which is the explanatory variable?

+ <span style="color:blue;">Explanatory: seeding (categorical - Seeded/Control)</span>
+ <span style="color:blue;">Response: action (categorical - Yawned/NoYawn)</span>

::: callout-note
### Descriptive Methods for Two Categorical Variables:

-   A **bar plot** gives a visual representation of the relationship between two categorical variables. A bar plot graphically presents the information given in the contingency table. The x-axis of the graph denotes the categories of the *explanatory variable*, and the *fill* color denotes the categories of the *response variable*. We can create three types of bar plots -- filled (my fav!), stacked, or dodged.

\vspace{0.1in}

-   A **contingency table** shows the joint counts (aka frequencies) of two categorical variables. The *rows* of the table denote the categories of the *response variable*, and the *columns* denote the categories of the *explanatory variable*.

:::

```{r}
#| echo: true
#| eval: false
ggplot(data = myth_busters, # <1>
       mapping = aes(x = seeding,  # <2>
                     fill = action # <3>
                     )
       ) + 
  geom_bar(position = "fill") +  # <4>
  labs(title = "Filled bar plot",  # <5>
       x = "Seeding Group",
       y = "Proportion of Subjects")
```

1.  Tell your plot which data set to get the information from.
2.  Tell the plot which variable you want on the x-axis (typically explanatory).
3.  Tell the plot which variable you want to color by (typically response).
4.  Create the bars and indicate `position = ` -- "fill", "stack", or "dodge".
5.  Provide appropriate plot titles and axis labels.

```{r}
#| echo: false
#| fig-pos: "H"
#| fig-width: 12
#| fig-height: 3
library(patchwork)
g_fill <- ggplot(data = myth_busters,
       mapping = aes(x = seeding,
                     fill = action)) +
  geom_bar(position = "fill") +
  labs(title = "Filled bar plot",
       x = "Seeding Group",
       y = "Proportion of Subjects"
       )

g_stack <- ggplot(data = myth_busters,
       mapping = aes(x = seeding,
                     fill = action)) +
  geom_bar(position = "stack") +
  labs(title = "Stacked bar plot",
       x = "Seeding Group",
       y = "Number of Subjects"
       )

g_dodge <- ggplot(data = myth_busters,
       mapping = aes(x = seeding,
                     fill = action)) +
  geom_bar(position = "dodge") +
  labs(title = "Dodged bar plot",
       x = "Seeding Group",
       y = "Number of Subjects"
       )

g_fill + g_stack + g_dodge
```
+ <span style="color:blue;">Notice the "filled" bar plot displays *proportions*. We can see that the NoYawn pink region (top) for the Control group (left) is about 80%. Thus, we observed about 80% of individuals in the control group did not yawn. </span>

+ <span style="color:blue;">The stacked and dodged bar plots show *counts*. We can see from the stacked bar plot that there were 16 total individuals in the control group and about 3 of them Yawned (blue bottom region on the left) </span>

Previously, we saw how we can summarize the counts from our data set using `count(VARIABLE)`. This is helpful, but notice we get one column for each count.

```{r}
#| echo: true
myth_busters |> # <1>
  count(seeding, action) # <2>
```

1.  Start with the `myth_busters` data set
2.  Count the number of subjects in each seeding group and yawn action combination

It is easier to understand the relationship between the explanatory and response variables if we arrange our counts into a contingency table. This displays our *observed counts*:

```{r}
#| echo: true
library(janitor)  # <1>

myth_busters |> # <2>
  tabyl(action, seeding) |>  # <3>
  adorn_totals(where = c("row", "col"))  # <4>
```

1. Load the `janitor` package to access specific functions.
2. Start with the `myth_busters` data set.
3. Use the `tabyl` function to count the number of subjects in each yawn action and seeding group combination, and arrange in a contingency table format.
4. Use the `adorn_totals()` function to add total counts to the contingency table.

\vspace{0.1in}

3.  Find the proportion that yawn in the Control group.

$$\hat p_{yawned|control}= $$<span style="color:blue;">11/35 = 0.324</span>

2.  Find the proportion that yawn in the Seeded group.

$$\hat p_{yawned|seeded}=$$ <span style="color:blue;">3/16 - 0.188</span>

::: callout-note
Two variables are associated or related if the value of one variable gives you information about the value of the other variable. When comparing two groups this means that the proportions or means take different values in the two groups.
:::

3. Do the two variables (seeded group and yawn action) seem to be related?

<span style="color:blue;">We just found these above.. We observed the chance that an individual in the seeded group yawned (32%) is about double the chance an individual in the control group yawned (18%). The two variables Seeded and Action might be related. Let's test it!</span>

We could instead obtain our *observed proportion* that yawn (and did not yawn) for each group using `adorn_percentages()`.

```{r}
#| echo: true
myth_busters |> 
  tabyl(action, seeding) |> 
  adorn_totals(where = c("row", "col")) |> 
  adorn_percentages(denominator = "col") # <5>
```

5.  Calculate the *observed proportions* based on the "col" totals (number of subjects in each seeding group).

### Chi-square Test of Independence

The above descriptive analysis tells us what we have learned about the 50 subjects in the study. Can we make any inferences beyond what happened in the study (i.e., general statements about the population)? Similar to what we did in Chapter 3 with the Chi-square Goodness of Fit Test for one categorical variable with more than two groups, we will be simulating and calculating a Chi-Squared Test Statistic to compare what we observed in the data to what we would have expected to see under the assumption that yawn seeding has no relationship with yawn action (i.e., if the null hypothesis is true).

4.  Write the null and alternative hypotheses for this study.

+ <span style="color:blue;">Null: There *is no relationship/association* between the seeding group and the action for **all** individuals.</span>
+ <span style="color:blue;">Alt: There *is a relationship/association* between the seeding group and the action for **all** individuals.</span>

::: callout-note
### Expected Counts under the assumption the null is true

The Chi-Squared Test Statistic ($X^2$) has exactly the same formula to what we used last week.

$$
\text{Test Statistic} =X^2 = \sum\frac{\text{(Observed - Expected)}^2}{\text{Expected}} 
$$

The only aspect that changes is how we get each cell's expected count. To find the *expected count* for each cell in our contingency table:

$$\frac{\text{row total}}{\text{total sample size}} \times \text{col total}.$$

The $\frac{\text{row total}}{\text{total sample size}}$ gives you the proportion of Response 1 (e.g., No yawn) in the entire sample regardless of explanatory variable group (e.g., regardless of Control or Seeded). Then assuming that is the expected probability of Outcome 1, we can distribute out the $n$ in each group to get the expected count (under the null) by multiplying by the $\text{col total}.$
:::

Once we have each of these, we can create a table of what counts we would have expected *under* the assumption there is no relationship between seeding group and yawn action (i.e., if the null is true).

5.  Complete the table of Expected counts.

**Observed counts**

```{r}
#| echo: false
myth_busters |> 
  tabyl(action, seeding) |>  
  adorn_totals(where = c("row", "col"))  |> 
  knitr::kable()
```

**Expected counts** under assumption null is true (no relationship between seeding and action)


+---------------------+---------------------------------+------------------------------+--------------+
|                     | Control                         | Seeded                       | Total        |
+---------------------+---------------------------------+------------------------------+--------------+
| No yawn             | $\frac{36}{50}\cdot16=11.52$    | $\frac{36}{50}\cdot34=24.48$ | 36           |
|                     | \                               |                              |              |
+---------------------+---------------------------------+------------------------------+--------------+
| Yawned              | $\frac{14}{50}\cdot16=4.48$     | $\frac{14}{50}\cdot34=9.52$  | 14           |
|                     | \                               |                              |              |
+---------------------+---------------------------------+------------------------------+--------------+
| Total               | 16                              | 34                           | 50           |
+---------------------+---------------------------------+------------------------------+--------------+

<span style="color:blue;">Note: the smallest expected count is for the Control Yawned group because the control group has the smallest number of individuals (16 < 34) and the yawned response had the smallest number of individuals (14 < 36)</span>

**Chi-Square Test Statistic** Next, we compare each of our observed counts to what we would have expected under the assumption there is no relationship between seeding and yawn action.

$$
X^2 =\frac{(13-11.52)^2}{11.52}+\frac{(3-4.48)^2}{4.48}+\frac{(23-24.48)^2}{24.48}+\frac{(11-9.52)^2}{9.52}=0.999
$$

<span style="color:blue;">This is our *observed* chi-square test statistic!</span>

\newpage

#### Conducting a Simulation Study with Two Variables

We will answer the research question by replicating the experiment over and over again, but *under* the assumption that yawn seeding has no relationship with yawn action (i.e., the null is true). We'll start with 14 yawners and 36 non-yawners, and we'll randomly assign 34 of these 50 subjects to the seeded group and the remaining 16 to the non-seeded group.

**Step 1:** Write the action (yawned / no yawn) and the seeding (seeded / control) on <span style="color:blue;">50</span> cards.

**Step 2:** Assume the null hypothesis is true (no relationship) and <span style="color:blue;">rip apart the observed pairs (breaking the relationship)</span>.

**Step 3:** Create a new data set that could have happened if $H_0$ was true by <span style="color:blue;">shuffling and randomly rematching to create simulated pairs assuming "no relationship" (null true)</span>.

**Step 4:** Construct the contingency table of your simulated counts from the shuffled/randomly matched cards to show the number of yawners and controls in each seeding group.

**Simulated Counts**

+---------------------+--------------+--------------+--------------+
|                     | Control      | Seeded       | Total        |
+---------------------+--------------+--------------+--------------+
| No yawn             | 11           | 25           | 36           |
|                     | \            |              |              |
+---------------------+--------------+--------------+--------------+
| Yawned              | 5            | 9            | 14           |
|                     | \            |              |              |
+---------------------+--------------+--------------+--------------+
| Total               | 16           | 34           | 50           |
+---------------------+--------------+--------------+--------------+

<span style="color:blue;">Note: yours will be different because simulation is a random process!</span>

6. Divide your simulated counts by the column totals to give you the proportion of individuals who yawned and did not yawn for each seeding group. Sketch these in the second plot below. How do your simulated proportions compare to the observed proportions?

```{r}
#| out-width: 80%
#| fig-align: center
#| fig-pos: "H"
knitr::include_graphics("04-images/yawn-bar-sketch.png")
```

+ <span style="color:blue;">simulated under the null: $\hat p_{yawned | control}$ = 5/16 = 0.3125</span>
+ <span style="color:blue;">simulated under the null: $\hat p_{yawned | seeded}$ = 9/34 = 0.264</span>


<span style="color:blue;">Recall, regardless of what group individuals are in, we expected 14/50 = 0.28 to yawn.</span>

**Step 5:** Calculate the $X^2$ text statistic for your simulated counts *under* the assumption there is no relationship between seeding group and yawn action.

*Recall our expected counts will be the same for every simulation (and the same as for our observed test statistic calculation).*

<span style="color:blue;">Simulated $X^2 =\frac{(11-11.52)^2}{11.52}+\frac{(5-4.48)^2}{4.48}+\frac{(25-24.48)^2}{24.48}+\frac{(9-9.52)^2}{9.52}=0.12$</span>

**Step 6:** Plot the simulated $X^2$ test statistic on the dot plot below.

```{r}
#| out-width: 80%
#| fig-align: center
#| fig-pos: "H"
knitr::include_graphics("04-images/yawn-dot-sketch.png")
```

7.  How does the observed test statistic compare to the simulated test statistics by your group members? Does this provide evidence for or against the alternative? Explain.

<span style="color:blue;">The observed $X^2 = 0.999$ is fairly consistent with the $X^2$ test statistics simulated under the assumtion there is no relationship between the seeding and action variables. We will likely fail to reject the null.</span>

We can conduct a large scale simulation using `Online Simulation Applets` \> `Two-way Tables`.

-   Clear \> Copy/Paste in the data <https://raw.githubusercontent.com/earobinson95/stat218-calpoly/refs/heads/main/01-course-notes/data/myth-yawns.csv>
-   Click `Use Data`
-   Click `Show Shuffle Options`
-   Change `Statistic` to $X^2$.
-   Change `Number of Shuffles` to 1000, and hit `Shuffle`

```{r}
#| out-width: 70%
#| fig-align: center
#| fig-pos: "H"
knitr::include_graphics("04-images/yawn-sim.PNG")
```

8. What does each "dot" on the above plot represent?

<span style="color:blue;">The $X^2$ test statistic for a sample of 50 subjects simulated assuming there is no relationship between yawning and action.</span>

9. How often did we see results at least as extreme as the observed test statistic under assumption the null is true? Estimate the p-value from the simulation. What decision would you make about the research question?

<span style="color:blue;">p-value = 0.469. Note this is greater than the $\alpha$ cutoff of 0.05 -> fail to reject the null</span>

10. State your conclusion in terms of the research question.

<span style="color:blue;">At an $\alpha = 0.05$, we *do not have enough evidence to conclude* there is a relationship between the seeding group and yawn action ($X^2$ = 0.999, p-value = 0.469).</span>

#### Using The Chi-Square Distribution

Recall the Chi-square distribution can be used to approximate our simulated null sampling distribution of the test statistic to test for a relationship between the explanatory and response variables. The Chi-square distribution takes on only positive numbers. In addition, this distribution is indexed by its degrees of freedom (or df).

::: callout-note
## Degrees of Freedom (df) for the Chi-Square Test of Independence:
When the null hypothesis is true, the test-statistic follows the Chi-square distribution with df = (rows - 1)(columns - 1).
:::

The R code below would be used to conduct a Chi-square Test for the Myth Busters study:

```{r}
#| echo: true
#| warning: true
library(infer) # <1>
chisq_test(x = myth_busters, # <2>
           explanatory = seeding, # <3>
           response = action, # <4>
           correct = FALSE  # <5>
           )
```

1. Load the `infer` package to access specific functions.
2. Use the `chisq_test()` function and denote the data set `x = `.
3. Specify the `explanatory = ` variable name,
4. and the `response = ` variable name.
5. We will not talk about corrections, but the default is `TRUE` and we want `FALSE`.

::: callout-note
### Conditions for conducting a Chi-square Test:

In order for the $\chi^2$ distribution to be a good approximation of the null sampling distribution, we need to verify two conditions:

-   Independent observations
-   At least 5 expected counts in each category

If the condition about expected cell counts is violated, we are forced to use the simulation-based method.
:::

11. Check the conditions for using a Chi-square distribution to analyze the Myth Buster's study. Is it appropriate to conduct a Chi-square Test?

+ <span style="color:blue;">Independent observations: the yawn action from one subject does not influence the yawn action of another (in the room separately).</span>
+ <span style="color:blue;">"Large enough sample size": The smallest expected count is 4.48 (this is actually less than 5).</span>

<span style="color:blue;">Since our "large enough sample size" condition is not met, it is not appropriate to use the Chi-Square distribution. We must rely on simulation!</span>

Notice the plot below shows the Chi-square distribution is not a very good approximation of our simulated sampling distribution of our test statistic. Therefore, we want to be cautious about using the theory-based Chi-square Test. <span style="color:blue;">USE SIMULATION INSTEAD! Simulation always works (as long as you have independence) since it does not rely on a mathematical distribution approximation for the null sampling distribution.</span>

```{r}
#| out-width: 40%
#| fig-align: center
#| fig-pos: "H"
knitr::include_graphics("04-images/yawn-chisq-approx.PNG")
```

```{r}
#| echo: true
#| warning: true
set.seed(93401)
library(infer)
chisq_test(x = myth_busters,
           explanatory = seeding,
           response = action,
           correct = FALSE,
           simulate.p.value = TRUE # <6>
           )
```

6. In order to conduct a *simulation* instead, specify `simulate.p.value = TRUE`. Notice we no longer have `chisq_df`.


## Observational Studies vs. Designed Experiments

Recall the concept of a *confounding variable*, a characteristic other than the variable of interest that may be related to the outcome. 

::: callout-note
## Definitions
-   An **observational study** involves collecting and analyzing data without manipulating or randomly assigning treatments. The data exists naturally, and we can only identify *associations* between variables.

-   A **designed experiment**, however, involves randomly assigning treatments or groups to individuals to investigate whether the treatment *causes* a change in the response variable. The study is manipulated to control other variables.
:::

::: callout-tip
## Key statistical idea:
In **observational studies**, we can only establish that an *association* exists between the explanatory and response variables. This is because other uncontrolled factors, or confounding variables, could influence the response. Since these factors aren’t balanced between groups, they might explain the observed differences.

\vspace{0.1in}

In **designed experiments**, *random assignment* helps balance confounding variables across treatment groups, controlling for their influence. Therefore, designed experiments can provide evidence of a *cause-and-effect* relationship.
:::

## Example 4.2: Vested Interest and Task Performance

*This example is from Investigating Statistical Concepts, Applications, and Methods by Beth Chance and Allan Rossman. 2006. Thomson-Brooks/Cole.*

"A study published in the Journal of Personality and Social Psychology (Butler and Baumeister, 1998) investigated a conjecture that having an observer with a vested interest would decrease subjects' performance on a skill-based task. Subjects were given time to practice playing a video game that required them to navigate an obstacle course as quickly as possible. They were then told to play the game one final time with an observer present. Subjects were randomly assigned to one of two groups. One group (Vested Interest) was told that the participant and observer would each win \$3 if the participant beat a certain threshold time, and the other group (No Vested Interest) was told only that the participant would win the prize if the threshold were beaten. The threshold was chosen to be a time that they beat in 30% of their practice turns. The following results are very similar to those found in the experiment: 3 of the 12 subjects in group A beat the threshold, and 8 of 12 subjects in group B achieved success."

|                         | Vested Interest  | No Vested Interest      | Total |
|-------------------------|:----------------:|:-----------------------:|:-----:|
| Achieved Success        |        3         |            8            |  11   |
| Did not achieve success |        9         |            4            |  13   |
| Total                   |       12         |           12            |  24   |

**Research Question:** Does whether the observer has a vested interest or not have an impact on performance on a skill-based task?

1.  What are the variables in the study? Are they categorical or numerical? Which is the explanatory variable? Which is the response variable?

\vspace{0.8in}

2.  Convert the research question into your null and alternative hypotheses.

\vspace{1.2in}


3. Is it appropriate to use the Chi-square distribution or do we need to use simulation?

\vspace{0.8in}

4.  Using the observed $X^2 = 4.196$ and the simulation output below, determine the p-value. Make a decision concerning the null hypothesis.

```{r}
#| out-width: 50%
#| fig-align: center
knitr::include_graphics("04-images/vested-interest-sim.PNG")
```

\vspace{0.8in}

5.  At an $\alpha = 0.10$, write a conclusion in terms of the original research question. Make sure to include your evidence in your conclusion.

\vspace{1.5in}

6. Suppose all 12 individuals in the Vested Interest group hold high scores on Mario Cart and all 12 individuals in the No Vested Interest group are new to playing video games. Why would this be problematic? 

\vspace{1.5in}

7. The scenario states that subject's were *randomly* assigned to one of two groups. How does this ensure we are actually evaluating how vested interest is related to the success of the video game rather than say skill? 

\vspace{1.5in}

8. If we determined that having a vested interest does have a relationship with achieving an outcome or not, does this allow us to draw a cause-and-effect conclusion between vested interest and success?

\vspace{1.5in}


## Example 4.3: Home Court Advantage

Sports teams prefer to play in front of their own fans rather than at the opposing team’s site. Having a sell-out crowd should provide even more excitement and lead to an even better performance, right? Well, consider the Oklahoma City Thunder, a National Basketball Association (NBA) team, in its second season (2008–2009) after moving from Seattle. This team had a win–loss record that was actually worse for home games with a sell-out crowd (3 wins and 15 losses) than for home games without a sell-out crowd (12 wins and 11 losses). (These data were noted in the April 20, 2009, issue of Sports Illustrated in the Go Figure column.)


1. Identify the observational unit and variables in this study. Also classify each variable as categorical (specify levels) or numeric.

+ Observational Unit:

\vspace{0.15in}

+ Explanatory Variable:

\vspace{0.15in}

+ Response Variable:

\vspace{0.15in}

2. Complete the observed counts in the contingency table below:

|                         | Sell-out Crowd   | Smaller Crowd           | Total |
|-------------------------|:----------------:|:-----------------------:|:-----:|
| Win                     |                  |                         |       |
| Loss                    |                  |                         |       |
| Total                   |                  |                         |       |

3. When did the Thunder have a higher winning percentage: in front of a sell-out crowd or a smaller crowd? Support your answer by calculating the proportion of sell-out games that they won and also the proportion of non-sell-out games that they won.

$$\hat p_{win|sell-out} = $$

\vspace{0.15in}

$$\hat p_{win|smaller} = $$

\vspace{0.15in}

4. Do the two variables appear to be associated? Explain.

\vspace{0.3in}

There are two possible explanations for this odd finding that the team had a better winning percentage with smaller crowds:
+ The sell-out crowd caused the Thunder to play worse, perhaps because of pressure or nervousness.
+ The sell-out crowd did not cause a worse performance, and some other issue (variable) explains why they had a worse winning percentage with sell-out crowds. In other words, a third variable is at play, which is related to both the crowd size and the game outcome.

(Of course, another explanation is random chance, but as we saw with the Chi-Square Test of Independence, we can test for this and will later rule out random chance in this case.)

5. Consider the second explanation. Suggest a plausible alternative variable that would explain why the team would be less likely to win in front of a sell-out crowd than in front of a smaller crowd. (Make sure it’s clear not just that your explanation would affect the team’s likelihood of winning but also that the team would be less likely to win in front of a sell-out crowd compared to a smaller crowd.)

\vspace{0.5in}

::: callout-note
### Definition

A **confounding variable** is a variable that is related both to the explanatory and to the response variable in such a way that its effects on the response variable cannot be separated from the effects of the explanatory variable.
:::

6. Identify the confounding variable based on your suggested explanation above. Explain how it is confounding: what is the link between this third variable and the response variable, and what is the link between this third variable and the explanatory variable? (Hint: Remember that this variable has to be recorded on the observational units: home games for the Thunder (i.e., legit variable).)

\vspace{0.5in}


Another variable recorded for these data was whether the opponent had a winning record the previous season. Of the Thunder’s 41 home games, 22 were against teams that won more than half of their games. Let’s refer to those 22 teams as "strong opponents". Of these 22 games, 13 were sell-outs. Of the 19 games against opponents that won less than half of their games that season (weak opponents), only 5 of those games were sell-outs.

7. Was the Thunder more likely to have a sell-out crowd against a strong opponent or a weak opponent? Calculate the relevant (conditional) proportions to support your answer.

$$\hat p_{sell-out|strong} = $$


$$\hat p_{sell-out|weak} = $$

When the Thunder played a strong opponent, they won only 4 of 22 games. When they played a weak opponent, the Thunder won 11 of 19 games.

8. Was the Thunder less likely to win against a strong opponent than a weak one? Again calculate the relevant (conditional) proportions to support your answer.

$$\hat p_{win|strong} = $$


$$\hat p_{win|weak} = $$

9. Explain how your answers to the previous two questions establish that strength of opponent is a confounding variable that prevents drawing a cause-and-effect conclusion between crowd size and game outcome.

\vspace{1.2in}

10. Although we did not carry out a Chi-square test of independence, summarize your conclusion about whether these data provide evidence that a sell-out crowd caused the Thunder to play worse. Write as if to a friend who has never studied statistics. Be sure to address the fact that the Thunder had a much smaller winning percentage in front of a sell-out crowd.

\vspace{1.2in}


::: callout-note
### Key statistical idea
Confounding explains why you cannot draw a cause-and-effect conclusion from association alone: The groups defined by the explanatory variable could differ in more ways than just the explanatory variable when confounding is present. The diagram below illustrates the confounding in the Thunder study. The top panel shows the study design: Observational units (home games) are sorted into groups according to the explanatory variable (whether
the arena was sold out). Then the response (win/lose) was observed. The bottom panel shows the confounding: sell-out crowds tended to be against stronger opponents; weaker opponents tended not to sell out the arena.

```{r}
# out-width: 50%
knitr::include_graphics("04-images/thunder-confounding.jpg")
```

:::



<!-- ## Example 4.3 High-Salt Diets and Cardiovascular Disease -->

<!-- Suppose a retrospective study is carried out among men aged 50-54 in a specific county who died over a one-month period. The investigators try to include approximately an equal number of men who died from CVD (the cases) and men who died from other causes (the controls). Of 15 people who died from CVD, 4 were on a high-salt diet before they died. In contrast, of 15 people who died from other causes, only 1 was on a high-salt diet. The data are shown in the following contingency table: -->

<!-- |         |           |          |       | -->
<!-- |---------|:---------:|:--------:|:-----:| -->
<!-- |         | High-Salt | Low-Salt | Total | -->
<!-- | Non-CVD |     1     |    14    |  15   | -->
<!-- | CVD     |     4     |    11    |  15   | -->
<!-- | Total   |     5     |    25    |  30   | -->

<!-- **Research Question:** Is there an association between the cause of death and salt diet? In other words, is the proprtion of the CVD group which has a high-salt diet different from the proportion of the Non-CVD group which has a high-salt diet? -->

<!-- 1.  What are the variables in the study? Which is the response variable? Which is the explanatory variable? -->

<!-- \vspace{0.8in} -->

<!-- 2.  Convert the research question into your null and alternative hypotheses. -->

<!-- \vspace{1.2in} -->

<!-- 3. Is it appropriate to use the Chi-square distribution or do we need to use simulation? -->

<!-- \vspace{0.8in} -->

<!-- 4.  Using the simulation output below, determine the p-value. Make a decision concerning the null hypothesis. -->

<!-- ```{r} -->
<!-- #| out-width: 50% -->
<!-- #| fig-align: center -->
<!-- knitr::include_graphics("04-images/cvd-sim.PNG") -->
<!-- ``` -->

<!-- \vspace{0.8in} -->

<!-- 5.  Write a conclusion in terms of the original research question. Make sure to include your evidence in your conclusion. -->

<!-- \vspace{1.5in} -->

<!-- In the *"Vested Interest and Task Performance"* study, participants were randomly assigned to groups, making this a designed experiment. The randomization likely balanced out other factors that could influence performance, meaning the reduced performance in the vested interest group is most likely *caused* by the vested interest itself. -->

<!-- \vspace{0.1in} -->

<!-- In contrast, the *"High-Salt Diet and Cardiovascular Disease"* study is an observational study. Other factors, like overall health behaviors (e.g., exercise habits), could explain the *association* between a high-salt diet and cardiovascular disease. Therefore, we can’t confidently conclude causation from this study. -->

<!-- ## Example 4.4: Alcoholism and Depression -->

<!-- Past research has suggested a high rate of alcoholism in families among patients with primary unipolar depression. A study of 210 families of females with primary unipolar depression found that 89 families had alcoholism present. A set of 299 control families found 94 present. -->

<!-- **Research Question:** Does the proportion of families afflicted by alcoholism differ between those families in which the female has primary unipolar depression and the control group? That is, is there a relationship between unipolar depression in females and alocholism in the family? -->

<!-- ```{r simulate-data2} -->
<!-- #| include: false -->
<!-- #| eval: false -->
<!-- library(tidyverse) -->

<!-- set.seed(56156) -->
<!-- alcoholism <- tibble(id = sample(1:509, 509), -->
<!--                        combo = c(rep("Control-Yes", 94), -->
<!--                                  rep("Depression-Yes", 89), -->
<!--                                  rep("Control-No", 205), -->
<!--                                  rep("Depression-No", 121) -->
<!--                                  ) -->

<!-- ) |>  -->
<!--   separate_wider_delim(cols = combo, names =  c("group", "alcoholism"), delim = "-") |>  -->
<!--   arrange(id) |>  -->
<!--   select(-id) -->

<!-- write.csv(alcoholism, "data/alcoholism.csv", row.names = F) -->
<!-- ``` -->

<!-- ```{r} -->
<!-- alcoholism <- read_csv("data/alcoholism.csv") -->
<!-- ``` -->

<!-- ```{r} -->
<!-- alcoholism |>  -->
<!--   tabyl(group, alcoholism) |> -->
<!--   adorn_totals(where = c("row", "col")) |>  -->
<!--   knitr::kable() -->
<!-- ``` -->

<!-- 1.  What are the variables in the study? Which is the response variable? Which is the explanatory variable? -->

<!-- \vspace{0.8in} -->

<!-- 2.  Identify the proportion of families afflicted by Alcoholism in both groups. -->

<!-- \vspace{1.2in} -->

<!-- 3.  Convert the research question into your null and alternative hypotheses. -->

<!-- \vspace{1.2in} -->

<!-- 4. Is it appropriate to use the Chi-square distribution or do we need to use simulation? -->

<!-- \vspace{0.8in} -->


<!-- 5.  Is there evidence there a relationship between unipolar depression in females and alocholism in the family? Use the R output to answer this question. Make sure to include evidence in your conclusion. -->

<!-- ```{r} -->
<!-- #| echo: true -->
<!-- library(infer) -->
<!-- chisq_test(alcoholism, -->
<!--            response = alcoholism, -->
<!--            explanatory = group, -->
<!--            correct = FALSE -->
<!--            ) -->
<!-- ``` -->

<!-- \vspace{1.2in} -->

<!-- 6.  Can we say that having unipolar depression *causes* alcoholism? Explain your reasoning. -->

<!-- \vspace{1.2in} -->

\newpage

::: callout-tip
## Key statistical idea: Scope of Inference


The **scope of inference** in a study refers to what conclusions can be drawn based on how the data were collected. If a study uses random assignment, it allows for causal conclusions because differences in outcomes can be attributed to the treatment or group. However, random sampling allows for results to be generalized to the broader population. Without random assignment, we can only infer associations, not causation, and without random sampling, the findings can only be applied to the specific sample studied, limiting generalizability.

```{r}
knitr::include_graphics("04-images/scope-of-inference.png")
```

:::